 ----- TRAINING CLASSIFIERS ----- 
Method:  concat 
Window size:  300 
Model type:  sktime.clustering.k_means.TimeSeriesKMeans 
Grid search params:  {'averaging_method': ['mean'], 'init_algorithm': ['kmeans++', 'forgy'], 'metric': ['euclidean', 'dtw'], 'n_clusters': [2]}
Fitting 5 folds for each of 4 candidates, totalling 20 fits
[CV 4/5] END averaging_method=mean, init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.587, test=0.625) total time=   0.2s
[CV 3/5] END averaging_method=mean, init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.567, test=0.573) total time=   0.2s
[CV 2/5] END averaging_method=mean, init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.551, test=0.619) total time=   0.2s
[CV 1/5] END averaging_method=mean, init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.534, test=0.546) total time=   0.2s
[CV 5/5] END averaging_method=mean, init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.853, test=0.857) total time=   0.2s
[CV 5/5] END averaging_method=mean, init_algorithm=kmeans++, metric=euclidean, n_clusters=2;, score=(train=0.852, test=0.857) total time=   0.4s
[CV 1/5] END averaging_method=mean, init_algorithm=kmeans++, metric=euclidean, n_clusters=2;, score=(train=0.552, test=0.546) total time=   0.4s
[CV 2/5] END averaging_method=mean, init_algorithm=kmeans++, metric=euclidean, n_clusters=2;, score=(train=0.672, test=0.561) total time=   0.4s
[CV 3/5] END averaging_method=mean, init_algorithm=kmeans++, metric=euclidean, n_clusters=2;, score=(train=0.822, test=0.813) total time=   0.4s
[CV 4/5] END averaging_method=mean, init_algorithm=kmeans++, metric=euclidean, n_clusters=2;, score=(train=0.641, test=0.659) total time=   0.4s
[CV 2/5] END averaging_method=mean, init_algorithm=kmeans++, metric=dtw, n_clusters=2;, score=(train=0.612, test=0.617) total time= 1.1min
[CV 3/5] END averaging_method=mean, init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.614, test=0.610) total time= 1.3min
[CV 5/5] END averaging_method=mean, init_algorithm=kmeans++, metric=dtw, n_clusters=2;, score=(train=0.614, test=0.610) total time= 1.6min
[CV 3/5] END averaging_method=mean, init_algorithm=kmeans++, metric=dtw, n_clusters=2;, score=(train=0.582, test=0.647) total time= 6.8min
[CV 5/5] END averaging_method=mean, init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.664, test=0.592) total time=11.8min
[CV 2/5] END averaging_method=mean, init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.629, test=0.706) total time=17.0min
[CV 1/5] END averaging_method=mean, init_algorithm=kmeans++, metric=dtw, n_clusters=2;, score=(train=0.537, test=0.548) total time=22.3min
[CV 1/5] END averaging_method=mean, init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.581, test=0.623) total time=27.2min
[CV 4/5] END averaging_method=mean, init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.622, test=0.610) total time=32.6min
Best estimator saved

------------------------------------------------

Method:  concat 
Window size:  300 
Model type:  sktime.clustering.k_medoids.TimeSeriesKMedoids 
Grid search params:  {'init_algorithm': ['forgy', 'random'], 'metric': ['euclidean', 'dtw'], 'n_clusters': [2]}
Fitting 5 folds for each of 4 candidates, totalling 20 fits
[CV 4/5] END averaging_method=mean, init_algorithm=kmeans++, metric=dtw, n_clusters=2;, score=(train=0.599, test=0.610) total time=37.8min
[CV 1/5] END init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.550, test=0.651) total time=   0.3s
[CV 2/5] END init_algorithm=random, metric=euclidean, n_clusters=2;, score=(train=0.548, test=0.580) total time=   0.3s
[CV 5/5] END init_algorithm=random, metric=euclidean, n_clusters=2;, score=(train=0.729, test=0.702) total time=   0.4s
[CV 1/5] END init_algorithm=random, metric=euclidean, n_clusters=2;, score=(train=0.550, test=0.651) total time=   0.4s
[CV 4/5] END init_algorithm=random, metric=euclidean, n_clusters=2;, score=(train=0.628, test=0.666) total time=   0.4s
[CV 5/5] END init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.556, test=0.627) total time=   0.4s
[CV 3/5] END init_algorithm=random, metric=euclidean, n_clusters=2;, score=(train=0.576, test=0.546) total time=   0.4s
[CV 2/5] END init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.680, test=0.601) total time=   0.4s
[CV 3/5] END init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.576, test=0.546) total time=   0.4s
[CV 4/5] END init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.607, test=0.645) total time=   0.4s
[CV 2/5] END init_algorithm=random, metric=dtw, n_clusters=2;, score=(train=0.522, test=0.631) total time= 1.2min
[CV 3/5] END init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.801, test=0.793) total time= 1.2min
[CV 2/5] END init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.583, test=0.546) total time= 1.3min
[CV 4/5] END init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.788, test=0.846) total time= 1.3min
[CV 4/5] END init_algorithm=random, metric=dtw, n_clusters=2;, score=(train=0.788, test=0.846) total time= 1.3min
[CV 5/5] END init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.577, test=0.570) total time= 1.3min
[CV 5/5] END init_algorithm=random, metric=dtw, n_clusters=2;, score=(train=0.534, test=0.595) total time= 1.3min
[CV 1/5] END init_algorithm=random, metric=dtw, n_clusters=2;, score=(train=0.639, test=0.562) total time= 1.3min
[CV 3/5] END init_algorithm=random, metric=dtw, n_clusters=2;, score=(train=0.660, test=0.647) total time= 1.3min
[CV 1/5] END init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.698, test=0.672) total time= 1.3min
[CV 1/5] END feature_selection=chi2;, score=(train=1.000, test=0.763) total time= 2.3min
[CV 2/5] END feature_selection=chi2;, score=(train=1.000, test=0.903) total time= 2.4min
[CV 4/5] END feature_selection=chi2;, score=(train=1.000, test=0.924) total time= 2.4min
[CV 3/5] END feature_selection=chi2;, score=(train=1.000, test=0.903) total time= 2.4min
[CV 5/5] END feature_selection=chi2;, score=(train=1.000, test=0.773) total time= 2.4min
Best estimator saved

------------------------------------------------

Method:  concat 
Window size:  300 
Model type:  sktime.classification.dictionary_based._boss.BOSSEnsemble 
Grid search params:  {'feature_selection': ['chi2', 'none']}
Fitting 5 folds for each of 2 candidates, totalling 10 fits
Best estimator saved

------------------------------------------------

Method:  concat 
Window size:  300 
Model type:  sktime.classification.distance_based._shape_dtw.ShapeDTW 
Grid search params:  {'shape_descriptor_function': ['raw', 'paa']}
Fitting 5 folds for each of 2 candidates, totalling 10 fits
[CV 3/5] END shape_descriptor_function=paa;, score=(train=1.000, test=0.793) total time=  50.0s
[CV 5/5] END shape_descriptor_function=paa;, score=(train=1.000, test=0.819) total time=  50.5s
[CV 1/5] END shape_descriptor_function=paa;, score=(train=1.000, test=0.719) total time=  49.7s
[CV 2/5] END shape_descriptor_function=paa;, score=(train=1.000, test=0.849) total time=  49.8s
[CV 4/5] END shape_descriptor_function=paa;, score=(train=1.000, test=0.852) total time=  49.6s
[CV 5/5] END feature_selection=none;, score=(train=1.000, test=0.808) total time= 3.2min
[CV 2/5] END shape_descriptor_function=raw;, score=(train=1.000, test=0.765) total time=  53.9s
[CV 4/5] END feature_selection=none;, score=(train=1.000, test=0.905) total time= 3.2min
[CV 5/5] END shape_descriptor_function=raw;, score=(train=1.000, test=0.728) total time=  54.8s
[CV 1/5] END feature_selection=none;, score=(train=1.000, test=0.942) total time= 3.2min
[CV 4/5] END shape_descriptor_function=raw;, score=(train=1.000, test=0.791) total time=  55.2s
[CV 2/5] END feature_selection=none;, score=(train=1.000, test=0.903) total time= 3.1min
[CV 1/5] END shape_descriptor_function=raw;, score=(train=1.000, test=0.648) total time=  54.3s
[CV 3/5] END feature_selection=none;, score=(train=1.000, test=0.810) total time= 3.3min
[CV 3/5] END shape_descriptor_function=raw;, score=(train=1.000, test=0.774) total time=  54.3s
Best estimator saved

------------------------------------------------

Method:  difference 
Window size:  300 
Model type:  sktime.clustering.k_means.TimeSeriesKMeans 
Grid search params:  {'averaging_method': ['mean'], 'init_algorithm': ['kmeans++', 'forgy'], 'metric': ['euclidean', 'dtw'], 'n_clusters': [2]}
Fitting 5 folds for each of 4 candidates, totalling 20 fits
Best estimator saved

------------------------------------------------

Method:  difference 
Window size:  300 
Model type:  sktime.clustering.k_medoids.TimeSeriesKMedoids 
Grid search params:  {'init_algorithm': ['forgy', 'random'], 'metric': ['euclidean', 'dtw'], 'n_clusters': [2]}
Fitting 5 folds for each of 4 candidates, totalling 20 fits
Best estimator saved

------------------------------------------------

Method:  difference 
Window size:  300 
Model type:  sktime.classification.dictionary_based._boss.BOSSEnsemble 
Grid search params:  {'feature_selection': ['chi2', 'none']}
Fitting 5 folds for each of 2 candidates, totalling 10 fits
Best estimator saved

------------------------------------------------

Method:  difference 
Window size:  300 
Model type:  sktime.classification.distance_based._shape_dtw.ShapeDTW 
Grid search params:  {'shape_descriptor_function': ['raw', 'paa']}
Fitting 5 folds for each of 2 candidates, totalling 10 fits
[CV 2/5] END averaging_method=mean, init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.828, test=0.908) total time=  10.0s
[CV 5/5] END averaging_method=mean, init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.847, test=0.888) total time=  10.3s
[CV 3/5] END averaging_method=mean, init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.848, test=0.813) total time=  10.2s
[CV 1/5] END averaging_method=mean, init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.820, test=0.926) total time=  10.5s
[CV 4/5] END averaging_method=mean, init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.870, test=0.740) total time=  10.5s
[CV 5/5] END averaging_method=mean, init_algorithm=kmeans++, metric=dtw, n_clusters=2;, score=(train=0.847, test=0.888) total time=  12.8s
[CV 3/5] END averaging_method=mean, init_algorithm=kmeans++, metric=dtw, n_clusters=2;, score=(train=0.848, test=0.813) total time=  12.8s
[CV 2/5] END averaging_method=mean, init_algorithm=kmeans++, metric=dtw, n_clusters=2;, score=(train=0.828, test=0.908) total time=  12.7s
[CV 4/5] END averaging_method=mean, init_algorithm=kmeans++, metric=dtw, n_clusters=2;, score=(train=0.874, test=0.740) total time=  13.6s
[CV 1/5] END averaging_method=mean, init_algorithm=kmeans++, metric=dtw, n_clusters=2;, score=(train=0.820, test=0.926) total time=  14.3s
[CV 1/5] END init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.814, test=0.835) total time=   0.4s
[CV 4/5] END init_algorithm=random, metric=euclidean, n_clusters=2;, score=(train=0.816, test=0.796) total time=   0.4s
[CV 3/5] END init_algorithm=random, metric=euclidean, n_clusters=2;, score=(train=0.846, test=0.775) total time=   0.4s
[CV 5/5] END init_algorithm=random, metric=euclidean, n_clusters=2;, score=(train=0.820, test=0.813) total time=   0.4s
[CV 2/5] END init_algorithm=random, metric=euclidean, n_clusters=2;, score=(train=0.822, test=0.872) total time=   0.4s
[CV 2/5] END init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.822, test=0.872) total time=   0.4s
[CV 1/5] END init_algorithm=random, metric=euclidean, n_clusters=2;, score=(train=0.814, test=0.835) total time=   0.4s
[CV 3/5] END init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.846, test=0.775) total time=   0.4s
[CV 4/5] END init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.816, test=0.796) total time=   0.5s
[CV 5/5] END init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.820, test=0.813) total time=   0.5s
[CV 1/5] END init_algorithm=random, metric=dtw, n_clusters=2;, score=(train=0.856, test=0.836) total time=  15.9s
[CV 2/5] END init_algorithm=random, metric=dtw, n_clusters=2;, score=(train=0.882, test=0.890) total time=  16.2s
[CV 5/5] END init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.870, test=0.942) total time=  16.3s
[CV 4/5] END init_algorithm=random, metric=dtw, n_clusters=2;, score=(train=0.857, test=0.850) total time=  16.4s
[CV 5/5] END init_algorithm=random, metric=dtw, n_clusters=2;, score=(train=0.870, test=0.942) total time=  16.4s
[CV 1/5] END init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.856, test=0.836) total time=  16.6s
[CV 3/5] END init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.884, test=0.868) total time=  17.2s
[CV 3/5] END init_algorithm=random, metric=dtw, n_clusters=2;, score=(train=0.884, test=0.868) total time=  17.3s
[CV 4/5] END init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.857, test=0.850) total time=  18.2s
[CV 2/5] END init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.882, test=0.890) total time=  18.4s
Best estimator saved

------------------------------------------------

Method:  ai 
Window size:  300 
Model type:  sktime.clustering.k_means.TimeSeriesKMeans 
Grid search params:  {'averaging_method': ['mean'], 'init_algorithm': ['kmeans++', 'forgy'], 'metric': ['euclidean', 'dtw'], 'n_clusters': [2]}
Fitting 5 folds for each of 4 candidates, totalling 20 fits
[CV 5/5] END averaging_method=mean, init_algorithm=kmeans++, metric=euclidean, n_clusters=2;, score=(train=0.861, test=0.869) total time=   0.4s
[CV 4/5] END shape_descriptor_function=paa;, score=(train=1.000, test=0.846) total time=  25.1s
[CV 2/5] END averaging_method=mean, init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.855, test=0.908) total time=   0.2s
[CV 1/5] END shape_descriptor_function=paa;, score=(train=1.000, test=0.756) total time=  25.3s
[CV 3/5] END averaging_method=mean, init_algorithm=kmeans++, metric=euclidean, n_clusters=2;, score=(train=0.875, test=0.793) total time=   0.4s
[CV 3/5] END shape_descriptor_function=paa;, score=(train=1.000, test=0.751) total time=  25.3s
[CV 2/5] END averaging_method=mean, init_algorithm=kmeans++, metric=euclidean, n_clusters=2;, score=(train=0.846, test=0.908) total time=   0.4s
[CV 2/5] END shape_descriptor_function=paa;, score=(train=1.000, test=0.846) total time=  25.6s
[CV 4/5] END averaging_method=mean, init_algorithm=kmeans++, metric=euclidean, n_clusters=2;, score=(train=0.874, test=0.796) total time=   0.4s
[CV 5/5] END shape_descriptor_function=paa;, score=(train=1.000, test=0.804) total time=  25.6s
Best estimator saved

------------------------------------------------

Method:  ai 
Window size:  300 
Model type:  sktime.clustering.k_medoids.TimeSeriesKMedoids 
Grid search params:  {'init_algorithm': ['forgy', 'random'], 'metric': ['euclidean', 'dtw'], 'n_clusters': [2]}
Fitting 5 folds for each of 4 candidates, totalling 20 fits
Best estimator saved

------------------------------------------------

Method:  ai 
Window size:  300 
Model type:  sktime.classification.dictionary_based._boss.BOSSEnsemble 
Grid search params:  {'feature_selection': ['chi2', 'none']}
Fitting 5 folds for each of 2 candidates, totalling 10 fits
Best estimator saved

------------------------------------------------

Method:  ai 
Window size:  300 
Model type:  sktime.classification.distance_based._shape_dtw.ShapeDTW 
Grid search params:  {'shape_descriptor_function': ['raw', 'paa']}
Fitting 5 folds for each of 2 candidates, totalling 10 fits
[CV 1/5] END feature_selection=chi2;, score=(train=1.000, test=0.842) total time=  55.8s
[CV 1/5] END averaging_method=mean, init_algorithm=kmeans++, metric=euclidean, n_clusters=2;, score=(train=0.861, test=0.871) total time=   0.2s
[CV 5/5] END feature_selection=chi2;, score=(train=1.000, test=0.816) total time=  56.6s
[CV 2/5] END averaging_method=mean, init_algorithm=kmeans++, metric=euclidean, n_clusters=2;, score=(train=0.874, test=0.908) total time=   0.2s
[CV 3/5] END feature_selection=chi2;, score=(train=1.000, test=0.683) total time=  57.5s
[CV 5/5] END averaging_method=mean, init_algorithm=kmeans++, metric=euclidean, n_clusters=2;, score=(train=0.893, test=0.833) total time=   0.2s
[CV 2/5] END feature_selection=chi2;, score=(train=1.000, test=0.662) total time=  57.0s
[CV 4/5] END averaging_method=mean, init_algorithm=kmeans++, metric=euclidean, n_clusters=2;, score=(train=0.866, test=0.924) total time=   0.2s
[CV 4/5] END feature_selection=chi2;, score=(train=1.000, test=0.684) total time=  57.7s
[CV 3/5] END averaging_method=mean, init_algorithm=kmeans++, metric=euclidean, n_clusters=2;, score=(train=0.879, test=0.869) total time=   0.3s
[CV 4/5] END averaging_method=mean, init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.866, test=0.924) total time=   0.2s
[CV 1/5] END averaging_method=mean, init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.861, test=0.871) total time=   0.2s
[CV 3/5] END averaging_method=mean, init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.866, test=0.869) total time=   0.2s
[CV 5/5] END averaging_method=mean, init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.888, test=0.833) total time=   0.2s
[CV 2/5] END averaging_method=mean, init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.874, test=0.908) total time=   0.2s
[CV 2/5] END averaging_method=mean, init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.856, test=0.872) total time=  10.2s
[CV 3/5] END averaging_method=mean, init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.826, test=0.869) total time=  10.8s
[CV 4/5] END averaging_method=mean, init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.862, test=0.851) total time=  10.8s
[CV 5/5] END averaging_method=mean, init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.861, test=0.851) total time=  11.0s
[CV 4/5] END feature_selection=none;, score=(train=1.000, test=0.834) total time= 1.4min
[CV 5/5] END averaging_method=mean, init_algorithm=kmeans++, metric=dtw, n_clusters=2;, score=(train=0.861, test=0.851) total time=  12.4s
[CV 3/5] END feature_selection=none;, score=(train=1.000, test=0.885) total time= 1.3min
[CV 2/5] END averaging_method=mean, init_algorithm=kmeans++, metric=dtw, n_clusters=2;, score=(train=0.856, test=0.872) total time=  12.7s
[CV 1/5] END averaging_method=mean, init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.865, test=0.853) total time=  12.2s
[CV 5/5] END feature_selection=none;, score=(train=1.000, test=0.882) total time= 1.4min
[CV 3/5] END averaging_method=mean, init_algorithm=kmeans++, metric=dtw, n_clusters=2;, score=(train=0.826, test=0.869) total time=  12.8s
[CV 2/5] END feature_selection=none;, score=(train=1.000, test=0.814) total time= 1.4min
[CV 4/5] END averaging_method=mean, init_algorithm=kmeans++, metric=dtw, n_clusters=2;, score=(train=0.862, test=0.851) total time=  12.9s
[CV 1/5] END feature_selection=none;, score=(train=1.000, test=0.832) total time= 1.3min
[CV 1/5] END averaging_method=mean, init_algorithm=kmeans++, metric=dtw, n_clusters=2;, score=(train=0.865, test=0.853) total time=  13.7s
[CV 4/5] END init_algorithm=random, metric=euclidean, n_clusters=2;, score=(train=0.784, test=0.796) total time=   0.4s
[CV 3/5] END init_algorithm=random, metric=euclidean, n_clusters=2;, score=(train=0.848, test=0.833) total time=   0.4s
[CV 5/5] END init_algorithm=random, metric=euclidean, n_clusters=2;, score=(train=0.826, test=0.758) total time=   0.4s
[CV 2/5] END init_algorithm=random, metric=euclidean, n_clusters=2;, score=(train=0.778, test=0.818) total time=   0.4s
[CV 3/5] END init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.848, test=0.833) total time=   0.4s
[CV 4/5] END init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.784, test=0.796) total time=   0.4s
[CV 1/5] END init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.783, test=0.800) total time=   0.4s
[CV 5/5] END init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.826, test=0.758) total time=   0.4s
[CV 1/5] END init_algorithm=random, metric=euclidean, n_clusters=2;, score=(train=0.783, test=0.800) total time=   0.4s
[CV 2/5] END init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.778, test=0.818) total time=   0.5s
[CV 2/5] END init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.877, test=0.832) total time=  15.7s
[CV 3/5] END init_algorithm=random, metric=dtw, n_clusters=2;, score=(train=0.846, test=0.833) total time=  15.6s
[CV 3/5] END init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.846, test=0.833) total time=  15.8s
[CV 2/5] END init_algorithm=random, metric=dtw, n_clusters=2;, score=(train=0.877, test=0.832) total time=  16.1s
[CV 5/5] END init_algorithm=random, metric=dtw, n_clusters=2;, score=(train=0.852, test=0.813) total time=  16.7s
[CV 1/5] END init_algorithm=random, metric=dtw, n_clusters=2;, score=(train=0.841, test=0.962) total time=  16.7s
[CV 4/5] END init_algorithm=random, metric=dtw, n_clusters=2;, score=(train=0.828, test=0.888) total time=  16.8s
[CV 4/5] END init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.803, test=0.832) total time=  16.8s
[CV 5/5] END init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.852, test=0.813) total time=  17.3s
[CV 1/5] END init_algorithm=forgy, metric=dtw, n_clusters=2;, score=(train=0.841, test=0.962) total time=  17.5s
[CV 4/5] END feature_selection=chi2;, score=(train=1.000, test=0.846) total time=  56.5s
[CV 5/5] END feature_selection=chi2;, score=(train=1.000, test=0.866) total time=  57.7s
[CV 3/5] END feature_selection=chi2;, score=(train=1.000, test=0.882) total time=  57.6s
[CV 2/5] END feature_selection=chi2;, score=(train=1.000, test=0.835) total time=  58.7s
[CV 1/5] END feature_selection=chi2;, score=(train=1.000, test=0.794) total time=  58.8s
[CV 3/5] END feature_selection=none;, score=(train=1.000, test=0.905) total time= 1.3min
[CV 4/5] END feature_selection=none;, score=(train=1.000, test=0.804) total time= 1.3min
[CV 1/5] END feature_selection=none;, score=(train=1.000, test=0.786) total time= 1.3min
[CV 2/5] END feature_selection=none;, score=(train=1.000, test=0.851) total time= 1.3min
[CV 5/5] END feature_selection=none;, score=(train=1.000, test=0.886) total time= 1.4min
[CV 3/5] END shape_descriptor_function=paa;, score=(train=1.000, test=0.668) total time=  25.2s
[CV 2/5] END shape_descriptor_function=paa;, score=(train=1.000, test=0.662) total time=  25.7s
[CV 4/5] END shape_descriptor_function=paa;, score=(train=1.000, test=0.729) total time=  25.9s
[CV 1/5] END shape_descriptor_function=paa;, score=(train=1.000, test=0.704) total time=  25.3s
[CV 5/5] END shape_descriptor_function=paa;, score=(train=1.000, test=0.785) total time=  25.5s
[CV 1/5] END averaging_method=mean, init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.851, test=0.926) total time=   0.2s
[CV 3/5] END shape_descriptor_function=raw;, score=(train=1.000, test=0.729) total time=  27.0s
[CV 3/5] END shape_descriptor_function=raw;, score=(train=1.000, test=0.610) total time=  26.1s
[CV 4/5] END averaging_method=mean, init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.870, test=0.796) total time=   0.2s
[CV 4/5] END shape_descriptor_function=raw;, score=(train=1.000, test=0.751) total time=  26.9s
[CV 5/5] END shape_descriptor_function=raw;, score=(train=1.000, test=0.774) total time=  26.2s
[CV 3/5] END averaging_method=mean, init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.879, test=0.793) total time=   0.2s
[CV 2/5] END shape_descriptor_function=raw;, score=(train=1.000, test=0.805) total time=  26.9s
[CV 4/5] END shape_descriptor_function=raw;, score=(train=1.000, test=0.600) total time=  26.0s
[CV 5/5] END averaging_method=mean, init_algorithm=forgy, metric=euclidean, n_clusters=2;, score=(train=0.861, test=0.869) total time=   0.2s
[CV 1/5] END shape_descriptor_function=raw;, score=(train=1.000, test=0.734) total time=  27.1s
[CV 1/5] END shape_descriptor_function=raw;, score=(train=1.000, test=0.617) total time=  26.2s
[CV 1/5] END averaging_method=mean, init_algorithm=kmeans++, metric=euclidean, n_clusters=2;, score=(train=0.846, test=0.926) total time=   0.4s
[CV 5/5] END shape_descriptor_function=raw;, score=(train=1.000, test=0.828) total time=  26.8s
[CV 2/5] END shape_descriptor_function=raw;, score=(train=1.000, test=0.698) total time=  26.3s
Best estimator saved

------------------------------------------------

 ----- TRAINING REGRESSOR ----- 
Loaded ->  Best_model/Trained_models/ai/300_seconds/TimeSeriesKMeans/gridsearch_cb762cccb4/best_estimator.zip
Loaded ->  Best_model/Trained_models/difference/300_seconds/TimeSeriesKMedoids/gridsearch_c42fbe82af/best_estimator.zip
Loaded ->  Best_model/Trained_models/concat/300_seconds/BOSSEnsemble/gridsearch_e52c627f3a/best_estimator.zip
Loaded ->  Best_model/Trained_models/ai/300_seconds/TimeSeriesKMedoids/gridsearch_c42fbe82af/best_estimator.zip
Loaded ->  Best_model/Trained_models/difference/300_seconds/TimeSeriesKMeans/gridsearch_cb762cccb4/best_estimator.zip
REGRESSOR: PATIENT  1 BEGIN
REGRESSOR: PATIENT  1 END
REGRESSOR: PATIENT  2 BEGIN
REGRESSOR: PATIENT  2 END
REGRESSOR: PATIENT  3 BEGIN
REGRESSOR: PATIENT  3 END
REGRESSOR: PATIENT  4 BEGIN
REGRESSOR: PATIENT  4 END
REGRESSOR: PATIENT  6 BEGIN
REGRESSOR: PATIENT  6 END
REGRESSOR: PATIENT  7 BEGIN
REGRESSOR: PATIENT  7 END
REGRESSOR: PATIENT  8 BEGIN
REGRESSOR: PATIENT  8 END
REGRESSOR: PATIENT  9 BEGIN
REGRESSOR: PATIENT  9 END
REGRESSOR: PATIENT  10 BEGIN
REGRESSOR: PATIENT  10 END
REGRESSOR: PATIENT  11 BEGIN
REGRESSOR: PATIENT  11 END
REGRESSOR: PATIENT  12 BEGIN
REGRESSOR: PATIENT  12 END
REGRESSOR: PATIENT  13 BEGIN
REGRESSOR: PATIENT  13 END
REGRESSOR: PATIENT  14 BEGIN
REGRESSOR: PATIENT  14 END
REGRESSOR: PATIENT  15 BEGIN
REGRESSOR: PATIENT  15 END
REGRESSOR: PATIENT  16 BEGIN
REGRESSOR: PATIENT  16 END
REGRESSOR: PATIENT  17 BEGIN
REGRESSOR: PATIENT  17 END
REGRESSOR: PATIENT  18 BEGIN
REGRESSOR: PATIENT  18 END
REGRESSOR: PATIENT  19 BEGIN
REGRESSOR: PATIENT  19 END
REGRESSOR: PATIENT  20 BEGIN
REGRESSOR: PATIENT  20 END
REGRESSOR: PATIENT  21 BEGIN
REGRESSOR: PATIENT  21 END
REGRESSOR: PATIENT  22 BEGIN
REGRESSOR: PATIENT  22 END
REGRESSOR: PATIENT  24 BEGIN
REGRESSOR: PATIENT  24 END
REGRESSOR: PATIENT  26 BEGIN
REGRESSOR: PATIENT  26 END
REGRESSOR: PATIENT  27 BEGIN
REGRESSOR: PATIENT  27 END
REGRESSOR: PATIENT  28 BEGIN
REGRESSOR: PATIENT  28 END
REGRESSOR: PATIENT  29 BEGIN
REGRESSOR: PATIENT  29 END
REGRESSOR: PATIENT  30 BEGIN
REGRESSOR: PATIENT  30 END
REGRESSOR: PATIENT  31 BEGIN
REGRESSOR: PATIENT  31 END
REGRESSOR: PATIENT  33 BEGIN
REGRESSOR: PATIENT  33 END
REGRESSOR: PATIENT  34 BEGIN
REGRESSOR: PATIENT  34 END
REGRESSOR: PATIENT  35 BEGIN
REGRESSOR: PATIENT  35 END
REGRESSOR: PATIENT  36 BEGIN
REGRESSOR: PATIENT  36 END
REGRESSOR: PATIENT  37 BEGIN
REGRESSOR: PATIENT  37 END
REGRESSOR: PATIENT  38 BEGIN
REGRESSOR: PATIENT  38 END
REGRESSOR: PATIENT  39 BEGIN
REGRESSOR: PATIENT  39 END
REGRESSOR: PATIENT  40 BEGIN
REGRESSOR: PATIENT  40 END
REGRESSOR: PATIENT  41 BEGIN
REGRESSOR: PATIENT  41 END
REGRESSOR: PATIENT  42 BEGIN
REGRESSOR: PATIENT  42 END
REGRESSOR: PATIENT  43 BEGIN
REGRESSOR: PATIENT  43 END
REGRESSOR: PATIENT  44 BEGIN
REGRESSOR: PATIENT  44 END
REGRESSOR: PATIENT  45 BEGIN
REGRESSOR: PATIENT  45 END
REGRESSOR: PATIENT  47 BEGIN
REGRESSOR: PATIENT  47 END
REGRESSOR: PATIENT  48 BEGIN
REGRESSOR: PATIENT  48 END
REGRESSOR: PATIENT  49 BEGIN
REGRESSOR: PATIENT  49 END
REGRESSOR: PATIENT  50 BEGIN
REGRESSOR: PATIENT  50 END
REGRESSOR: PATIENT  51 BEGIN
REGRESSOR: PATIENT  51 END
REGRESSOR: PATIENT  52 BEGIN
REGRESSOR: PATIENT  52 END
REGRESSOR: PATIENT  53 BEGIN
REGRESSOR: PATIENT  53 END
REGRESSOR: PATIENT  54 BEGIN
REGRESSOR: PATIENT  54 END
REGRESSOR: PATIENT  55 BEGIN
REGRESSOR: PATIENT  55 END
REGRESSOR: PATIENT  57 BEGIN
REGRESSOR: PATIENT  57 END
REGRESSOR: PATIENT  58 BEGIN
REGRESSOR: PATIENT  58 END
REGRESSOR: PATIENT  59 BEGIN
REGRESSOR: PATIENT  59 END
REGRESSOR: PATIENT  60 BEGIN
REGRESSOR: PATIENT  60 END
REGRESSOR: PATIENT  61 BEGIN
REGRESSOR: PATIENT  61 END
REGRESSOR: PATIENT  62 BEGIN
REGRESSOR: PATIENT  62 END
REGRESSOR: PATIENT  63 BEGIN
REGRESSOR: PATIENT  63 END
REGRESSOR: PATIENT  64 BEGIN
REGRESSOR: PATIENT  64 END
REGRESSOR: PATIENT  66 BEGIN
REGRESSOR: PATIENT  66 END
REGRESSOR: PATIENT  68 BEGIN
REGRESSOR: PATIENT  68 END
REGRESSOR: PATIENT  69 BEGIN
REGRESSOR: PATIENT  69 END
REGRESSOR: PATIENT  70 BEGIN
REGRESSOR: PATIENT  70 END
REGRESSOR: PATIENT  71 BEGIN
REGRESSOR: PATIENT  71 END
REGRESSOR: PATIENT  72 BEGIN
REGRESSOR: PATIENT  72 END
REGRESSOR: PATIENT  73 BEGIN
REGRESSOR: PATIENT  73 END
REGRESSOR: PATIENT  74 BEGIN
REGRESSOR: PATIENT  74 END
REGRESSOR: PATIENT  75 BEGIN
REGRESSOR: PATIENT  75 END
REGRESSOR: PATIENT  76 BEGIN
REGRESSOR: PATIENT  76 END
REGRESSOR: PATIENT  77 BEGIN
REGRESSOR: PATIENT  77 END
REGRESSOR: PATIENT  78 BEGIN
REGRESSOR: PATIENT  78 END
REGRESSOR: PATIENT  79 BEGIN
REGRESSOR: PATIENT  79 END
REGRESSOR: PATIENT  80 BEGIN
REGRESSOR: PATIENT  80 END
REGRESSOR: START FIT
REGRESSOR: END FIT
 ----- CREATING DASHBOARDS ----- 
Expected estimators:  5
Loading ->  Best_model/Trained_models/ai/300_seconds/TimeSeriesKMeans/gridsearch_cb762cccb4/best_estimator.zip
Loaded ->  Best_model/Trained_models/ai/300_seconds/TimeSeriesKMeans/gridsearch_cb762cccb4/best_estimator.zip
Loading ->  Best_model/Trained_models/difference/300_seconds/TimeSeriesKMedoids/gridsearch_c42fbe82af/best_estimator.zip
Loaded ->  Best_model/Trained_models/difference/300_seconds/TimeSeriesKMedoids/gridsearch_c42fbe82af/best_estimator.zip
Loading ->  Best_model/Trained_models/concat/300_seconds/BOSSEnsemble/gridsearch_e52c627f3a/best_estimator.zip
Loaded ->  Best_model/Trained_models/concat/300_seconds/BOSSEnsemble/gridsearch_e52c627f3a/best_estimator.zip
Loading ->  Best_model/Trained_models/ai/300_seconds/TimeSeriesKMedoids/gridsearch_c42fbe82af/best_estimator.zip
Loaded ->  Best_model/Trained_models/ai/300_seconds/TimeSeriesKMedoids/gridsearch_c42fbe82af/best_estimator.zip
Loading ->  Best_model/Trained_models/difference/300_seconds/TimeSeriesKMeans/gridsearch_cb762cccb4/best_estimator.zip
Loaded ->  Best_model/Trained_models/difference/300_seconds/TimeSeriesKMeans/gridsearch_cb762cccb4/best_estimator.zip
Patient  56
 - AHA:      100
 - HP:       [95.6989247311828, 97.84946236559139, 68.17204301075269, 93.11827956989247, 97.74193548387096]
 - AHA predicted from HP:  98.51397928451087
Patient  46
 - AHA:      100
 - HP:       [96.33113828786453, 97.74223894637818, 73.09501411100658, 89.18156161806209, 99.43555973659454]
 - AHA predicted from HP:  100
Patient  67
 - AHA:      87
 - HP:       [92.85714285714286, 95.88744588744589, 59.84848484848485, 93.72294372294373, 96.86147186147186]
 - AHA predicted from HP:  88.64030155391853
Patient  32
 - AHA:      75
 - HP:       [75.45541706615532, 49.664429530201346, 21.28475551294343, 61.07382550335571, 54.650047938638544]
 - AHA predicted from HP:  48.433853422613765
Patient  23
 - AHA:      64
 - HP:       [87.67772511848341, 89.57345971563981, 29.383886255924168, 73.64928909952607, 92.13270142180095]
 - AHA predicted from HP:  65.36442661702158
Patient  5
 - AHA:      53
 - HP:       [65.60000000000001, 63.709090909090904, 23.927272727272726, 44.07272727272728, 72.07272727272728]
 - AHA predicted from HP:  63.10205253841639
Patient  25
 - AHA:      42
 - HP:       [65.61351947097722, 50.69801616458487, 12.343864805290227, 17.48714180749449, 80.30859662013225]
 - AHA predicted from HP:  40.4355588629795
Patient  65
 - AHA:      33
 - HP:       [61.83035714285714, 59.70982142857143, 22.098214285714285, 40.848214285714285, 81.91964285714286]
 - AHA predicted from HP:  49.1946929422687
